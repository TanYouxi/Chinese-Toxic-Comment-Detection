{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyMAME0QF1DDNTmsVR6tY8w6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3CHSptTPNlYG"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import time\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, Flatten\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","\n","start_time=time.time()\n","\n","train_df = pd.read_csv(\"totaltr.csv\")\n","test_df = pd.read_csv(\"totalts.csv\")\n","\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(train_df['input'])\n","\n","# 转换文本为序列\n","train_df['input'] = tokenizer.texts_to_sequences(train_df['input'])\n","test_df['input'] = tokenizer.texts_to_sequences(test_df['input'])\n","\n","X_train, X_val, y_train, y_val = train_test_split(\n","    train_df['input'],\n","    train_df['output'],\n","    test_size=0.1,\n","    random_state=42\n",")\n","\n","X_train = pad_sequences(X_train, maxlen=100, dtype='float32')\n","X_val = pad_sequences(X_val, maxlen=100, dtype='float32')\n","X_test = pad_sequences(test_df['input'], maxlen=100, dtype='float32')\n","\n","y_train = np.asarray(y_train).astype('float32').reshape((-1, 1))\n","y_val = np.asarray(y_val).astype('float32').reshape((-1, 1))\n","y_test = np.asarray(test_df['output']).astype('float32').reshape((-1, 1))\n","\n","model = Sequential()\n","model.add(Embedding(len(tokenizer.index_word) + 1, input_length=100, output_dim=50))\n","model.add(Bidirectional(LSTM(100)))\n","model.add(Flatten())\n","model.add(Dense(250, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer=\"adam\", loss='binary_crossentropy', metrics=[\"accuracy\"])\n","\n","early_stop = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=True)\n","\n","history = model.fit(X_train, y_train, batch_size=64, epochs=7,\n","                    validation_data=(X_val, y_val), callbacks=[early_stop])\n","model.save('lstm_model.keras')\n","\n","y_pred_prob = model.predict(X_test)\n","y_pred = np.argmax(y_pred_prob, axis=1)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","precision = precision_score(y_test, y_pred, average='weighted')\n","\n","print(f'Accuracy: {accuracy:.4f}')\n","print(f'F1-score: {f1:.4f}')\n","print(f'Recall: {recall:.4f}')\n","print(f'Precision: {precision:.4f}')\n","results = model.evaluate(X_test, y_test, batch_size=64)\n","print(\"result: \", results)\n","\n","end_time=time.time()\n","total_time = end_time - start_time\n","print(f\"Total runtime of the script: {total_time:.4f} seconds\")\n"]}]}