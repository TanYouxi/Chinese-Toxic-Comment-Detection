{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyP4PxXLG42j76CstmFdD6Wi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n","from torch.optim import AdamW\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import time\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","\n","train_data = pd.read_csv('./data/your_input_file.csv')\n","test_data = pd.read_csv('./data/your_input_file.csv')\n","\n","train_texts, dev_texts, train_labels, dev_labels = train_test_split(\n","    train_data['input'].tolist(), train_data['output'].tolist(), test_size=0.1, random_state=42)\n","\n","test_texts = test_data['input'].tolist()\n","test_labels = test_data['output'].tolist()\n","\n","label_mapping = {'safe': 0, 'toxic': 1}\n","\n","train_labels = [label_mapping[label] for label in train_labels]\n","dev_labels = [label_mapping[label] for label in dev_labels]\n","test_labels = [label_mapping[label] for label in test_labels]\n","\n","class SentimentDataset(Dataset):\n","    def __init__(self, texts, labels, tokenizer, max_length=128):\n","        self.encodings = tokenizer(texts, truncation=True, padding=\"max_length\", max_length=max_length)\n","        self.labels = torch.tensor(labels)\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = self.labels[idx]\n","        return item\n","\n","from typing import List, Dict\n","\n","def train_transformers(model_name: str, max_length=128, num_labels=2, epochs=3):\n","    print(f\"\\n{'='*20} Training {model_name} {'='*20}\")\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","    if tokenizer.pad_token is None:\n","        tokenizer.pad_token = tokenizer.eos_token\n","\n","    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n","    model.config.pad_token_id = tokenizer.pad_token_id\n","    model.resize_token_embeddings(len(tokenizer))\n","\n","    train_dataset = SentimentDataset(train_texts, train_labels, tokenizer, max_length)\n","    dev_dataset = SentimentDataset(dev_texts, dev_labels, tokenizer, max_length)\n","    test_dataset = SentimentDataset(test_texts, test_labels, tokenizer, max_length)\n","\n","    optimizer = AdamW(model.parameters(), lr=2e-5)\n","\n","    accuracy_results, f1_results, recall_results, precision_results = [], [], [], []\n","    best_epoch, best_accuracy, best_f1, best_recall, best_precision = 0, 0.0, 0.0, 0.0, 0.0\n","\n","    for num_epochs in range(1, epochs + 1):\n","        training_args = TrainingArguments(\n","            output_dir=f'./results_{model_name}_{num_epochs}',\n","            num_train_epochs=num_epochs,\n","            per_device_train_batch_size=8,\n","            per_device_eval_batch_size=8,\n","            warmup_steps=500,\n","            weight_decay=0.01,\n","            logging_dir=f'./logs_{model_name}_{num_epochs}',\n","            evaluation_strategy=\"epoch\",\n","            save_strategy=\"epoch\",\n","            load_best_model_at_end=True,\n","            save_total_limit=2,\n","            logging_steps=500,\n","            report_to=\"none\",\n","        )\n","\n","        trainer = Trainer(\n","            model=model,\n","            args=training_args,\n","            train_dataset=train_dataset,\n","            eval_dataset=dev_dataset,\n","            optimizers=(optimizer, None)\n","        )\n","\n","        start_train_time = time.time()\n","        trainer.train()\n","        train_time = time.time() - start_train_time\n","\n","        start_infer_time = time.time()\n","        predictions = trainer.predict(test_dataset)\n","        infer_time = (time.time() - start_infer_time) / len(test_dataset)\n","\n","        y_pred = torch.argmax(torch.tensor(predictions.predictions), axis=1).numpy()\n","\n","        acc = accuracy_score(test_labels, y_pred)\n","        f1_weighted = f1_score(test_labels, y_pred, average='weighted')\n","        recall_weighted = recall_score(test_labels, y_pred, average='weighted')\n","        precision_weighted = precision_score(test_labels, y_pred, average='weighted')\n","        cm = confusion_matrix(test_labels, y_pred)\n","        num_params = sum(p.numel() for p in model.parameters())\n","\n","        print(f\"=== Epoch {num_epochs} ===\")\n","        print(f\"Accuracy: {acc:.4f} | F1-weighted: {f1_weighted:.4f} | Recall-weighted: {recall_weighted:.4f} | Precision-weighted: {precision_weighted:.4f}\")\n","        print(\"Confusion Matrix:\\n\", cm)\n","        print(f\"Model Params: {num_params}\")\n","        print(f\"Training Time: {train_time:.2f}s | Inference Time/sample: {infer_time:.4f}s\\n\")\n","\n","        accuracy_results.append(acc)\n","        f1_results.append(f1_weighted)\n","        recall_results.append(recall_weighted)\n","        precision_results.append(precision_weighted)\n","\n","        if acc > best_accuracy:\n","            best_epoch = num_epochs\n","            best_accuracy = acc\n","            best_f1 = f1_weighted\n","            best_recall = recall_weighted\n","            best_precision = precision_weighted\n","\n","    print(f\"\\nBEST Epoch: {best_epoch} | Accuracy: {best_accuracy:.4f} | F1: {best_f1:.4f} | Recall: {best_recall:.4f} | Precision: {best_precision:.4f}\")\n","    print(\"Accuracy Curve:\", accuracy_results)\n","    print(\"F1 Curve:\", f1_results)\n","    print(\"Recall Curve:\", recall_results)\n","    print(\"Precision Curve:\", precision_results)\n","\n","model_list = [\n","    'bert-base-uncased',\n","    'gpt2',\n","    'answerdotai/modernbert-base',\n","    'roberta-base',\n","    'microsoft/deberta-base'\n","]\n","\n","for model_name in model_list:\n","    train_transformers(model_name, max_length=128 if 'roberta' in model_name or 'deberta' in model_name else 64)\n"],"metadata":{"id":"Pc_USnnUA59r"},"execution_count":null,"outputs":[]}]}