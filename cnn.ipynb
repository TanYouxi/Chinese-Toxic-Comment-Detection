{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyPohv7ezI5PRdN0omVuHjAU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"F8_utDBoAN0Y"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import time\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","start_time=time.time()\n","\n","train_df = pd.read_csv('./data/your_input_file.csv')\n","test_df = pd.read_csv('./data/your_input_file.csv')\n","\n","texts = train_df['input']\n","labels = train_df['output']\n","\n","tokenizer = Tokenizer(num_words=5000)\n","tokenizer.fit_on_texts(texts)\n","X = tokenizer.texts_to_sequences(texts)\n","\n","X = pad_sequences(X, maxlen=100)\n","\n","X_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.1, random_state=42)\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n","model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Dropout(0.2))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n","\n","history = model.fit(X_train, y_train, epochs=12, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stop])\n","model.save('cnn_model.keras')\n","\n","X_test = tokenizer.texts_to_sequences(test_df['input'])\n","X_test = pad_sequences(X_test, maxlen=100)\n","y_test = test_df['output']\n","\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int)\n","\n","accuracy = accuracy_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","precision = precision_score(y_test, y_pred, average='weighted')\n","\n","print(f'Accuracy: {accuracy:.4f}')\n","print(f'F1-score: {f1:.4f}')\n","print(f'Recall: {recall:.4f}')\n","print(f'Precision: {precision:.4f}')\n","\n","end_time=time.time()\n","total_time = end_time - start_time\n","print(f\"Total runtime of the script: {total_time:.4f} seconds\")"]}]}