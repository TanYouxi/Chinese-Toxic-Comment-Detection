{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMczGrGaFYi5zZcK2TSQmGX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"O0iQMynhdGaE"},"outputs":[],"source":["import pandas as pd\n","import jieba\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","import warnings\n","from joblib import dump\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn import svm\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import LabelEncoder\n","\n","warnings.filterwarnings(\"ignore\", category=UserWarning)\n","\n","TRAIN_PATH = r\"totaltr.csv\"\n","TEST_PATH = r\"./data/totalts.csv\"  # please replace with your actual path\n","MODEL_SAVE_PATH = r\"./output/models\"  # please replace with your actual path\n","\n","os.makedirs(MODEL_SAVE_PATH, exist_ok=True)\n","\n","def chinese_text_preprocessor(text):\n","    if not isinstance(text, str):\n","        return \"\"\n","    words = jieba.cut(text)\n","    return ' '.join([word for word in words if len(word) > 1])\n","\n","def load_local_data(train_path, test_path):\n","    train_df = pd.read_csv(train_path)\n","    test_df = pd.read_csv(test_path)\n","\n","    print(\"✅ Training set loaded successfully!\")\n","    print(f\"Training set shape: {train_df.shape}\")\n","    print(f\"Training columns: {train_df.columns}\")\n","    print(\"\\nTraining sample:\")\n","    print(train_df.head())\n","\n","    print(\"\\n✅ Test set loaded successfully!\")\n","    print(f\"Test set shape: {test_df.shape}\")\n","    print(\"\\nTest sample:\")\n","    print(test_df.head())\n","\n","    return train_df, test_df\n","\n","def preprocess_chinese_data(df, text_col='input', label_col='output'):\n","    print(\"\\nMissing value statistics:\")\n","    print(df.isnull().sum())\n","\n","    df = df.dropna()\n","    df[text_col] = df[text_col].apply(chinese_text_preprocessor)\n","\n","    if df[label_col].dtype == 'object':\n","        le = LabelEncoder()\n","        df[label_col] = le.fit_transform(df[label_col])\n","        print(\"\\nLabel encoding applied.\")\n","\n","    return df[text_col], df[label_col]\n","\n","def train_and_evaluate_chinese(X_train, X_test, y_train, y_test):\n","    tfidf = TfidfVectorizer(\n","        max_features=10000,\n","        ngram_range=(1, 2),\n","        token_pattern=r'(?u)\\b\\w+\\b'\n","    )\n","\n","    models = {\n","        'Logistic Regression': LogisticRegression(max_iter=1000),\n","        'Naive Bayes': MultinomialNB(),\n","        'SVM': svm.LinearSVC(max_iter=1000, dual=False),\n","        'Decision Tree': DecisionTreeClassifier(max_depth=5)\n","    }\n","\n","    results = {}\n","\n","    for name, model in models.items():\n","        pipeline = Pipeline([\n","            ('tfidf', tfidf),\n","            ('clf', model)\n","        ])\n","\n","        print(f\"\\nTraining {name}...\")\n","        pipeline.fit(X_train, y_train)\n","        y_pred = pipeline.predict(X_test)\n","\n","        accuracy = accuracy_score(y_test, y_pred)\n","        report = classification_report(y_test, y_pred)\n","        cm = confusion_matrix(y_test, y_pred)\n","\n","        results[name] = {\n","            'model': pipeline,\n","            'accuracy': accuracy,\n","            'report': report,\n","            'confusion_matrix': cm\n","        }\n","\n","        print(f\"{name} Accuracy: {accuracy:.4f}\")\n","        print(f\"Classification Report:\\n{report}\")\n","\n","    return results\n","\n","def visualize_results(results):\n","    accuracies = {name: res['accuracy'] for name, res in results.items()}\n","    plt.figure(figsize=(10, 6))\n","    plt.bar(accuracies.keys(), accuracies.values())\n","    plt.title('Model Accuracy Comparison')\n","    plt.ylabel('Accuracy')\n","    plt.ylim(0, 1)\n","    for i, v in enumerate(accuracies.values()):\n","        plt.text(i, v + 0.02, f\"{v:.4f}\", ha='center')\n","    plt.show()\n","\n","    plt.figure(figsize=(15, 10))\n","    for i, (name, res) in enumerate(results.items(), 1):\n","        plt.subplot(2, 2, i)\n","        sns.heatmap(res['confusion_matrix'], annot=True, fmt='d', cmap='Blues')\n","        plt.title(f'{name} Confusion Matrix')\n","        plt.xlabel('Predicted')\n","        plt.ylabel('Actual')\n","    plt.tight_layout()\n","    plt.show()\n","\n","def save_all_models(results, save_dir=MODEL_SAVE_PATH):\n","    for name, res in results.items():\n","        model = res['model']\n","        model_dir = os.path.join(save_dir, f'model_{name}')\n","        os.makedirs(model_dir, exist_ok=True)\n","        model_path = os.path.join(model_dir, 'model.joblib')\n","        dump(model, model_path)\n","        print(f\"✅ Model {name} saved to: {model_path}\")\n","\n","def main():\n","    try:\n","        plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n","        plt.rcParams['axes.unicode_minus'] = False\n","    except:\n","        try:\n","            plt.rcParams['font.sans-serif'] = ['SimHei']\n","            plt.rcParams['axes.unicode_minus'] = False\n","        except Exception as e:\n","            print(e)\n","\n","    try:\n","        train_df, test_df = load_local_data(TRAIN_PATH, TEST_PATH)\n","    except Exception as e:\n","        print(e)\n","        return None, None\n","\n","    try:\n","        X_train, y_train = preprocess_chinese_data(train_df)\n","        print(\"\\nTraining data preprocessing completed.\")\n","    except Exception as e:\n","        print(f\"\\nTraining data preprocessing failed: {str(e)}\")\n","        return None, None\n","\n","    try:\n","        X_test, y_test = preprocess_chinese_data(test_df)\n","        print(\"\\nTest data preprocessing completed.\")\n","    except Exception as e:\n","        print(f\"\\nTest data preprocessing failed: {str(e)}\")\n","        return None, None\n","\n","    print(\"\\nTraining label distribution:\")\n","    print(pd.Series(y_train).value_counts(normalize=True))\n","\n","    print(\"\\nTest label distribution:\")\n","    print(pd.Series(y_test).value_counts(normalize=True))\n","\n","    try:\n","        results = train_and_evaluate_chinese(X_train, X_test, y_train, y_test)\n","    except Exception as e:\n","        print(e)\n","        return None, None\n","\n","    try:\n","        visualize_results(results)\n","    except Exception as e:\n","        print(e)\n","\n","    try:\n","        best_model_name = max(results, key=lambda k: results[k]['accuracy'])\n","        best_model = results[best_model_name]['model']\n","        best_accuracy = results[best_model_name]['accuracy']\n","        print(f\"\\nBest Model: {best_model_name} | Accuracy: {best_accuracy:.4f}\")\n","    except Exception as e:\n","        print(e)\n","        return None, None\n","\n","    try:\n","        save_all_models(results)\n","    except Exception as e:\n","        print(e)\n","\n","if __name__ == \"__main__\":\n","    best_model, model_path = main()\n"]}]}